# 🧠 Word Tokenization – NLP Project #01

Welcome to my **first mini AI project** in this daily series!  
This project focuses on one of the most fundamental tasks in **Natural Language Processing (NLP)** — **Word Tokenization**.

---

## 📌 What is Word Tokenization?

**Tokenization** is the process of splitting a stream of text into smaller meaningful units called **tokens**.  
In this project, we’ll break down input text into individual **words**, which is the first step in many NLP tasks such as:

- Sentiment analysis
- Text classification
- Machine translation
- Chatbots

---

## 🔧 Tech Stack

- 🐍 **Python**
- 📚 **NLTK** (Natural Language Toolkit)

---

## 🚀 Features

- Accepts user input (or reads from a file)
- Cleans and preprocesses the text
- Uses NLTK’s tokenizer to split the text into words
- Displays the list of word tokens
- Optionally shows token frequency

---

## 📂 File Structure

Branch-FirstProject
┣ 📄 WordTokenizationF.ipynb
┗ 📄 README.md


## 🧪 Sample Output

Input:
![image](https://github.com/user-attachments/assets/c2fc00d9-97d9-42ff-ab55-607c092609ee)
Output:
![image](https://github.com/user-attachments/assets/d3784090-ba97-4dac-a9cb-cb0a306946f8)

📦 How to Run
Install dependencies:
         pip install nltk
Run the script:
         python word_tokenizer.py

💡 What I Learned
How to load and clean text data
Using nltk.word_tokenize() for word-level tokenization
Why tokenization is essential in any NLP pipeline

"Every big AI model starts with understanding a sentence. This is Day 1!"
– Jonsi

## 📌 Connect with Me
- 💼 [LinkedIn](https://www.linkedin.com/in/jonsi-misharwal-24295b286/)
- ✉️ [Email](jonsimisharwal@gmail.com)
